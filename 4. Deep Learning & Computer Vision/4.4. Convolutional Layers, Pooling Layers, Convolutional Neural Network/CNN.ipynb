{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc7e788-61f8-475b-87d6-78f2601e4b45",
   "metadata": {},
   "source": [
    "# Seeing the world - Convolutional Neural Networks\n",
    "\n",
    "* Gordon.H | SHSID Data Science Group \n" ,
    "\n",
    "*Welcome back to the course, Junior ML Engineers !*\n",
    "\n",
    "Today we will be learning about the ultimate solution for image processing, **Convulutional Neural Netorks**\n",
    "\n",
    "---\n",
    "### Requirements \n",
    "* Understanding of the fundamentals of Machine learning\n",
    "* Basic Knowledge of Neural Networks\n",
    "* Basic Python and Numpy Library Usage\n",
    "\n",
    "---\n",
    "### 1. Problem with Images\n",
    "\n",
    "You have a small gray scale image of size 28*28 pixels\n",
    "* Size = 28*28 = 784\n",
    "* To feed it into a dense layer, we flatten into a vector of **784** numbers.\n",
    "* If first layer has 128 neurons we will need **100,352** weights\n",
    "\n",
    "This is a huge problem because:\n",
    "* It is inefficient with such large parameters to train\n",
    "* Spatial information is lost when we flatten the image\n",
    "\n",
    "Now, CNN's are designed to solve the problem with a smart approach\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    subgraph Dense Network Approach\n",
    "        A[Input Image<br>28x28x1] --> B{Flatten};\n",
    "        B --> C[1D Vector<br>784 neurons];\n",
    "        C --> D[Dense Layer];\n",
    "        style A fill:#f9f,stroke:#333,stroke-width:2px\n",
    "    end\n",
    "    \n",
    "    subgraph CNN Approach\n",
    "        E[Input Image<br>28x28x1] --> F{Convolutional Layer};\n",
    "        F --> G[Feature Map<br>e.g., 26x26x32];\n",
    "        style E fill:#9cf,stroke:#333,stroke-width:2px\n",
    "    end\n",
    "\n",
    "    A -- \"Loses spatial structure\" --> C\n",
    "    E -- \"Preserves spatial structure\" --> G\n",
    "```\n",
    "As you see, CNN keeps the image's 2D structure, allowing it to learn from pixel neighborhoods.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The core of CNN : Convolutional Layer\n",
    "\n",
    "Instead of looking at a large image at once, CNN looks at it in small chunks. \n",
    "\n",
    "A **filter** is a small matrix of weights that the network learns. The process of sliding the filter and computing the output is called a **convolution**.\n",
    "\n",
    "Here's a mini-example of a 2x2 filter sliding over a 3x3 image to produce a 2x2 feature map.\n",
    "\n",
    "```\n",
    "Input Image (I)      Filter (K)     Feature Map (O)\n",
    "+---+---+---+        +---+---+      +---+---+\n",
    "| 1 | 5 | 2 |        | 1 | 0 |      | 9 | ? |\n",
    "+---+---+---+        +---+---+      +---+---+\n",
    "| 8 | 1 | 6 |        | 1 | 0 |      | ? | ? |\n",
    "+---+---+---+        +---+---+      +---+---+\n",
    "| 3 | 4 | 7 |\n",
    "+---+---+---+\n",
    "```\n",
    "To calculate the top-left value of the output: `(1*1) + (5*0) + (8*1) + (1*0) = 9`.\n",
    "\n",
    "#### The Mathematical Logic\n",
    "\n",
    "The mathematical formula for such operation, **cross-correlation**, looks like this:\n",
    "$$\n",
    "O_{i,j} = b + \\sum_{u=0}^{F-1} \\sum_{v=0}^{F-1} I_{i+u, j+v} \\cdot K_{u,v}\n",
    "$$\n",
    "\n",
    "Looks complicated right? Lets break it down:\n",
    "\n",
    "*   $O_{i,j}$: The output value at row `i`, column `j` in the feature map.\n",
    "\n",
    "*   $b$: A learnable **bias** term, which helps the filter make better predictions.\n",
    "\n",
    "*   $\\sum$: The \"sum\" symbol. We sum over the filter's dimensions (`u` and `v`).\n",
    "\n",
    "*   $I_{i+u, j+v}$: A pixel value from the **Input** image patch.\n",
    "\n",
    "*   $K_{u,v}$: A weight from our **Kernel** (aka **the filter**).\n",
    "\n",
    "This formula is a precise mathematical formula for cross correlation in Machine Learning, in mathematics convolution is a bit different, it involves flipping the filter (both horizontally and vertically) before sliding it over the image. The reason for such difference is due to the special nature of neural networks, the values in the filter are learned during training, the network can simply learn the flipped version of the filter if it needs to. The cross correlation is easier to implement.\n",
    "\n",
    "#### Hyperparameters and Output Size\n",
    "The size of our output feature map depends on the hyperparameters we choose. The output width ($W_{out}$) and height ($H_{out}$) can be calculated with this formula:\n",
    "\n",
    "$$\n",
    "W_{out} = \\frac{W_{in} - F + 2P}{S} + 1\n",
    "$$\n",
    "$$\n",
    "H_{out} = \\frac{H_{in} - F + 2P}{S} + 1\n",
    "$$\n",
    "\n",
    "Where:\n",
    "*   $W_{in}, H_{in}$: Input width and height.\n",
    "*   $F$: Filter size.\n",
    "*   $P$: Padding (number of pixels added to the border).\n",
    "*   $S$: Stride (how many pixels the filter slides at a time).\n",
    "\n",
    "#### Example Code\n",
    " *Note: You can run the following code locally to try out convolutional layers!*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bcea1c-0c71-4fbe-9001-e63093a3fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to use pip to install numpy and matplotlib!\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define the Input and Filter\n",
    "# A simple 6x6 grayscale image. \n",
    "# It has a sharp vertical edge down the middle.\n",
    "# (Low values = dark, high values = light)\n",
    "input_image = np.array([\n",
    "    [10, 10, 10, 100, 100, 100],\n",
    "    [10, 10, 10, 100, 100, 100],\n",
    "    [10, 10, 10, 100, 100, 100],\n",
    "    [10, 10, 10, 100, 100, 100],\n",
    "    [10, 10, 10, 100, 100, 100],\n",
    "    [10, 10, 10, 100, 100, 100]\n",
    "])\n",
    "\n",
    "# A 3x3 filter designed to detect vertical edges.\n",
    "# The positive values on the left and negative on the right\n",
    "# will give a high response when we move from dark to light.\n",
    "vertical_edge_filter = np.array([\n",
    "    [ 1,  0, -1],\n",
    "    [ 2,  0, -2], # This is a \"Sobel\" filter, common in image processing\n",
    "    [ 1,  0, -1]\n",
    "])\n",
    "\n",
    "# 2. The Convolution Operation\n",
    "# Get dimensions (assuming no padding, stride=1)\n",
    "img_h, img_w = input_image.shape\n",
    "filter_h, filter_w = vertical_edge_filter.shape\n",
    "out_h = (img_h - filter_h) + 1\n",
    "out_w = (img_w - filter_w) + 1\n",
    "\n",
    "# Create an empty feature map to store the output\n",
    "output_feature_map = np.zeros((out_h, out_w))\n",
    "\n",
    "# Slide filter over the image\n",
    "for y in range(out_h):\n",
    "    for x in range(out_w):\n",
    "        # Get current patch of the image\n",
    "        image_patch = input_image[y : y + filter_h, x : x + filter_w]\n",
    "        \n",
    "        # Perform element-wise multiplication and sum the result\n",
    "        # This is the core of the convolution!\n",
    "        convolution_sum = np.sum(image_patch * vertical_edge_filter)\n",
    "        \n",
    "        # Store result in the map\n",
    "        output_feature_map[y, x] = convolution_sum       \n",
    "# 3.Display Results\n",
    "print(\"--- Manual NumPy Convolution ---\\n\")\n",
    "print(\"Input Image:\\n\", input_image)\n",
    "print(\"\\nVertical Edge Filter:\\n\", vertical_edge_filter)\n",
    "print(\"\\nOutput Feature Map:\\n\", output_feature_map)\n",
    "print(\"\\nNotice the high values in the output where the vertical edge was detected!\")\n",
    "# Visualize the images\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.imshow(input_image, cmap='gray')\n",
    "ax1.set_title(\"Original Image\")\n",
    "ax2.imshow(output_feature_map, cmap='gray')\n",
    "ax2.set_title(\"Feature Map (Edges)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70522ea-6596-413f-aadf-e37042a51b87",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Making it Robust: The Pooling layer\n",
    "\n",
    "A Pooling layer shrinks the feature map to make the network faster and robust. The most common type of pooling is **Max Pooling**.\n",
    "\n",
    "#### Visualizing Max Pooling\n",
    "\n",
    "Imagine a 2x2 Max Pooling operation on a 4x4 feature map.\n",
    "\n",
    "```\n",
    "Feature Map                     Pooled Output\n",
    "+---+---+---+---+               +---+---+\n",
    "|12 |20 | 30| 0 |  max(12,20,8,12)--> |20 |\n",
    "+---+---+---+---+               +---+---+\n",
    "| 8 |12 | 2 | 0 |  max(30,0,2,0)-->   |30 |\n",
    "+---+---+---+---+               +---+---+\n",
    "|34 |70 | 37| 4 |  max(34,70,112,100)-->|112|\n",
    "+---+---+---+---+               +---+---+\n",
    "|112|100| 25| 12|  max(37,4,25,12)--> |37 |\n",
    "+---+---+---+---+               +---+---+\n",
    "```\n",
    "This keeps only the strongest signal, reducing the map size from 4x4 to 2x2.\n",
    "\n",
    "#### The Math Behind Pooling\n",
    "\n",
    "Here is the formula for Max Pooling:\n",
    "\n",
    "$$\n",
    "P_{i,j} = \\max_{0 \\le u < F_p, 0 \\le v < F_p} A_{i \\cdot S_p + u, j \\cdot S_p + v}\n",
    "$$\n",
    "\n",
    "This formally states: \"The output $P_{i,j}$ is the `max` value from the input feature map `A` within the pooling window.\"\n",
    "\n",
    "---\n",
    "### Putting it all together: A full CNN Architecture\n",
    "\n",
    "A real world CNN stacks up all these layers\n",
    "\n",
    "``` mermaid\n",
    "graph LR\n",
    "    A[\"Input Image (28x28x1)\"] --> B[\"Conv2D Layer\\n32 filters, 3x3\\nOutput: 26x26x32\"]\n",
    "    B --> C[\"MaxPooling2D\\n2x2 window\\nOutput: 13x13x32\"]\n",
    "    C --> D[\"Conv2D Layer\\n64 filters, 3x3\\nOutput: 11x11x64\"]\n",
    "    D --> E[\"MaxPooling2D\\n2x2 window\\nOutput: 5x5x64\"]\n",
    "    E --> F[\"Flatten Layer\\nOutput: 1600 nodes\"]\n",
    "    F --> G[\"Dense Layer\\n128 nodes\"]\n",
    "    G --> H[\"Output Layer\\n10 nodes (Softmax)\"]\n",
    "\n",
    "    subgraph Feature Extractor\n",
    "        B; C; D; E;\n",
    "    end\n",
    "\n",
    "    subgraph Classifier\n",
    "        F; G; H;\n",
    "    end\n",
    "```\n",
    "The final layer uses a **Softmax** activation function to convert the network's scores into a probability distribution.\n",
    "\n",
    "The **Softmax** function for a specific output class `i` is:\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{z})_i = \\frac{e^{z_i}}{\\sum_{j=1}^{C} e^{z_j}}\n",
    "$$\n",
    "\n",
    "The formula gurantees that all output values are between 0 to 1 and sums up to be 1. This allows us to treat them as the model's confidence for each class.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Coding Example: Full Functional CNN Architecture\n",
    "\n",
    "The following example uses Pytorch and Matplotlib to create an example CNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a426d453-c908-4108-8af4-b896b9a8e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the CNN architecture\n",
    "class MNIST_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_CNN, self).__init__()\n",
    "        # Feature extractor\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3),  # 28x28x1 -> 26x26x32\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                   # 26x26x32 -> 13x13x32\n",
    "            nn.Conv2d(32, 64, kernel_size=3),  # 13x13x32 -> 11x11x64\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                    # 11x11x64 -> 5x5x64\n",
    "        )\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                      # 5x5x64 -> 1600\n",
    "            nn.Linear(5*5*64, 128),            # 1600 -> 128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)                 # 128 -> 10\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = MNIST_CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Load MNIST data\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_data = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=1000)\n",
    "\n",
    "# Training function\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                  f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "\n",
    "# Test function\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
    "          f'({accuracy:.0f}%)\\n')\n",
    "    return accuracy\n",
    "\n",
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "accuracies = []\n",
    "for epoch in range(1, 6):  # 5 epochs\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    acc = test(model, device, test_loader)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(range(1, 6), accuracies)\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd21d0-27ed-41c3-81a0-6fb694aeab29",
   "metadata": {},
   "source": [
    "### Summary & Conclusion\n",
    "\n",
    "**Congratulations!** You have just completed your lesson on Convolutional Neural Networks!\n",
    "\n",
    "Throughout this lesson you have learned:\n",
    "\n",
    "* How **Convolutional Layers** use filters to find features, and you've seen the formal math behind the process.\n",
    "* How **Pooling Layers** make the network robust and efficient.\n",
    "* Understanded the **CNN** architecture and has saw the code to build it.\n",
    "\n",
    "In the next lesson, we will learn about video data augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
